import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Vector;

public class Tokenizer {
	static Vector<TokenDef> definitions;

	static {
		definitions = new Vector<TokenDef>();
	}

	public static void run(String src, Vector<Token> tokens) {
		List<TokenMatch> matches = new ArrayList<TokenMatch>();
		for (TokenDef def : definitions) {
			findMatches(src, def, matches);
		}

		HashMap<Integer, List<TokenMatch>> groupedMatches = new HashMap<Integer, List<TokenMatch>>();
		for (TokenMatch match : matches) {
			if (groupedMatches.get(match.start) == null) {
				groupedMatches.put(match.start, new ArrayList<TokenMatch>());
			}
			groupedMatches.get(match.start).add(match);
		}

		TokenMatch lastMatch = null;
		for (int i : groupedMatches.keySet()) {
			Collections.sort<TokenMatch>(groupedMatches.get(i));
			
		}
	}

	private static void findMatches(String input, TokenDef def, List<TokenMatch> matches) {

	}

	public static class Token {
		public int type;
		public String val;
	}

	public static class TokenDef {
		public String regex;
		public int type;
		public int precedence;
	}

	public static class TokenMatch {
		public int type;
		public String val;
		public int start, end;
		public int precedence;
	}
}
